[
  {
    "path": "posts/2021-03-20-welcome-to-gunjans-blog/",
    "title": "Welcome to the Blog",
    "description": "Let's give this a whirl.",
    "author": [
      {
        "name": "Gunjan Payal",
        "url": {}
      },
      {
        "name": "Ambuj Gupta",
        "url": {}
      }
    ],
    "date": "2021-03-20",
    "categories": [],
    "contents": "\n\\[\n\\sigma = \\sqrt{ \\frac{1}{N} \\sum_{i=1}^N (x_i -\\mu)^2}\n\\] Distill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-03-20T13:01:24+05:30",
    "input_file": {}
  },
  {
    "path": "posts/2019-04-28-nflfastr-dbplyr-rsqlite/",
    "title": "Bigger, nflfastR, dbplyr",
    "description": "Doing more with dplyr and SQL",
    "author": [
      {
        "name": "Thomas Mock",
        "url": {}
      }
    ],
    "date": "2020-04-28",
    "categories": [
      "NFL",
      "nflscrapR",
      "nflfastR",
      "SQL",
      "tidyverse"
    ],
    "contents": "\n\nContents\nnflfastR\nMore data\n\nRead in the data\nEnter SQL\nCreate the SQLite database\n\ndbplyr\nOpen a connection\nQuery the database\nCollect the data\n\nTLDR\nAdditional Notes\n\n\nnflfastR\nBen Baldwin and Sebastian Carl released nflfastR yesterday to provide faster scraping of NFL play-by-play data as well as data all the way back to 2000! This builds upon the work of the nflscrapR team who paved the way for this data for NFL games between 2009 and 2019.\n\n\nINTRODUCING: @nflfastR, an R package for scraping NFL data faster ‚ö°üèà Play-by-play of all NFL games going back to 2000üèà Includes Completion Probability and CPOE going back to 2006üèà Fast functions for scraping team rosters and highlight videoshttps://t.co/sgrq8GdoWJ pic.twitter.com/fqbyE1pPHE\n\n‚Äî Ben Baldwin (@benbbaldwin) April 27, 2020\n\nMore data\nWith more data comes excitement - we can do new analysis with very similar code!\nHowever, the 2000-2019 data consists of ~2.25 GB of data, 291 variables and 903,998 rows‚Ä¶ this is 263,063,418 observations! While this is not anywhere close to too much for R to handle, it can start to feel a little intimidating to read it all into memory. I‚Äôll be covering some tooling to work with relatively larger datasets using the same dplyr tools you know and love!\nRead in the data\nBen and Sebastian were kind enough to provide all of the .RDS files for every year between 2000-2019 on GitHub for ease of download. With a quick purrr call we can download all 20 years of data and pull them into memory. We can also save them to local storage for offline access or to at least not need to re-download them down the line.\n\n\nlibrary(dplyr)\n\nread_pbp_rds <- function(year){\n  readRDS(url(glue::glue('https://raw.githubusercontent.com/guga31bb/nflfastR-data/master/data/play_by_play_{year}.rds')))\n}\n\nall_pbp <- 2000:2019 %>% \n  purrr::map_dfr(read_pbp_rds)\n  \nall_pbp %>% \n  write_rds(\"data/2000-2019_pbp_raw.rds\")\n\n\n\nHowever, as mentioned before this is ~ 2 GB of data in memory, which can take a while to download and/or read in especially if you do this multiple times as opposed to in just one session. Also - there are VERY few times where you actually need to pull in all of the specific columns and/or rows for your analysis, why waste time reading in data that you don‚Äôt need?\nEnter SQL\nNo no, I‚Äôm not going to make you learn SQL to work with this dataset, but we are going to use SQL inside R. Specifically, we‚Äôre going to play around with SQLite - in their own words:\n\nSQLite is a C-language library that implements a small, fast, self-contained, high-reliability, full-featured, SQL database engine. SQLite is the most used database engine in the world.\n\nWhat this provides for us is a super lightweight storage and query format that works nicely with R and dplyr. We don‚Äôt have to mess around with creating an entire database but rather have a small self-contained file that allows for many of the same SQL-features.\nFor a deeper dive on the RSQLite package, with basic and advanced usage check out the packagedown site. Additionally, the Data Carpentry guide is pretty similar to this guide but aimed at scientists.\nCreate the SQLite database\n\n\nlibrary(RSQLite)\nlibrary(DBI)\n\n# create the \"empty\" database\nmydb <- DBI::dbConnect(RSQLite::SQLite(), \"data/pbp_db.sqlite\")\nmydb\n\n\n\n\n\n# <SQLiteConnection>\n#   Path: /Users/thomasmock/nflscrapR/data/pbp_db.sqlite\n#   Extensions: TRUE\n\n\n\n\n\n# Write the in-memory data into the database as a table\nDBI::dbWriteTable(mydb, \"pbp_raw_2000-2019\", raw_pbp)\n\n# list the table\nDBI::dbListTables(mydb)\n\n\n\n\n\n# [1] \"pbp_raw_2000-2019\"\n\n\n\nOk - so to recap in about 2 lines of code we have created and populated a SQLite database solely through R. Now, the SQLite file is only around 1 GB compared to our 2 GB .RDS - so it‚Äôs more efficiently stored and allows us to do some other cool things as seen below.\ndbplyr\nNow the magic really happens: dplyr has a built-in package called dbplyr, this is a translation engine that lets you write dplyr code that is evaluated as SQL.\nFull details at the dbplyr site.\nThe basic concept is:\nConnect to a datasource/database\nQuery the database INSIDE the database or on disk\nPull the data into memory only when you‚Äôre ready\nOpen a connection\nWe can open the connection by calling tbl() on the database we have open (mydb) and indicating which table we want to query.\n\n\nlibrary(dbplyr)\n# Open a queryable connection with the database\npbp_db <- tbl(mydb, \"pbp_raw_2000-2019\")\n\npbp_db\n\n\n\n\n\n# Source:   table<pbp_raw_2000-2019> [?? x 291]\n# Database: sqlite 3.30.1 \n# [/Users/thomasmock/nflscrapR/data/pbp_db.sqlite]\n\n#   play_id game_id home_team away_team posteam posteam_type defteam side_of_field yardline_100\n#      <dbl>   <dbl> <chr>     <chr>     <chr>   <chr>        <chr>   <chr>                <dbl>\n#  1      34  2.00e9 NYG       ARI       NYG     home         ARI     NYG                     70\n#  2      70  2.00e9 NYG       ARI       ARI     away         NYG     NYG                     25\n#  3     106  2.00e9 NYG       ARI       ARI     away         NYG     ARI                     65\n#  4     131  2.00e9 NYG       ARI       ARI     away         NYG     ARI                     63\n#  5     148  2.00e9 NYG       ARI       ARI     away         NYG     ARI                     63\n#  6     165  2.00e9 NYG       ARI       ARI     away         NYG     ARI                     63\n#  7     190  2.00e9 NYG       ARI       NYG     home         ARI     NYG                     78\n#  8     211  2.00e9 NYG       ARI       NYG     home         ARI     NYG                     70\n#  9     232  2.00e9 NYG       ARI       NYG     home         ARI     NYG                     67\n# 10     253  2.00e9 NYG       ARI       NYG     home         ARI     NYG                     68\n# # ‚Ä¶ with more rows, and 282 more variables: game_date <dbl>, quarter_seconds_remaining <dbl>,\n# #   half_seconds_remaining <dbl>, game_seconds_remaining <dbl>, game_half <chr>,\n# #   quarter_end <dbl>, drive <dbl>, sp <dbl>, qtr <dbl>, down <chr>, goal_to_go <dbl>,\n# #   time <chr>, yrdln <chr>, ydstogo <dbl>, ydsnet <dbl>, desc <chr>, play_type <chr>,\n# #   yards_gained <dbl>, shotgun <dbl>, no_huddle <dbl>, qb_dropback <dbl>, qb_kneel <dbl>,\n# #   qb_spike <dbl>, qb_scramble <dbl>, pass_length <chr>, pass_location <chr>,\n# #   air_yards <dbl>, yards_after_catch <dbl>, run_location <chr>, run_gap <chr>,\n# #   field_goal_result <chr>, kick_distance <dbl>, extra_point_result <chr>,\n# #   two_point_conv_result <chr>, home_timeouts_remaining <dbl>,\n# #   away_timeouts_remaining <dbl>, timeout <dbl>, timeout_team <chr>, td_team <chr>,\n# #   posteam_timeouts_remaining <dbl>, defteam_timeouts_remaining <dbl>,\n# #   total_home_score <dbl>, total_away_score <dbl>, posteam_score <dbl>, defteam_score <dbl>,\n# #   score_differential <dbl>, posteam_score_post <dbl>, defteam_score_post <dbl>,\n# #   score_differential_post <dbl>, no_score_prob <dbl>, opp_fg_prob <dbl>,\n# #   opp_safety_prob <dbl>, opp_td_prob <dbl>, fg_prob <dbl>, safety_prob <dbl>,\n# #   td_prob <dbl>, extra_point_prob <dbl>, two_point_conversion_prob <dbl>, ep <dbl>,\n# #   epa <dbl>, total_home_epa <dbl>, total_away_epa <dbl>, total_home_rush_epa <dbl>,\n# #   total_away_rush_epa <dbl>, total_home_pass_epa <dbl>, total_away_pass_epa <dbl>,\n# #   air_epa <dbl>, yac_epa <dbl>, comp_air_epa <dbl>, comp_yac_epa <dbl>,\n# #   total_home_comp_air_epa <dbl>, total_away_comp_air_epa <dbl>,\n# #   total_home_comp_yac_epa <dbl>, total_away_comp_yac_epa <dbl>,\n# #   total_home_raw_air_epa <dbl>, total_away_raw_air_epa <dbl>, total_home_raw_yac_epa <dbl>,\n# #   total_away_raw_yac_epa <dbl>, wp <dbl>, def_wp <dbl>, home_wp <dbl>, away_wp <dbl>,\n# #   wpa <dbl>, home_wp_post <dbl>, away_wp_post <dbl>, total_home_rush_wpa <dbl>,\n# #   total_away_rush_wpa <dbl>, total_home_pass_wpa <dbl>, total_away_pass_wpa <dbl>,\n# #   air_wpa <dbl>, yac_wpa <dbl>, comp_air_wpa <dbl>, comp_yac_wpa <dbl>,\n# #   total_home_comp_air_wpa <dbl>, total_away_comp_air_wpa <dbl>,\n# #   total_home_comp_yac_wpa <dbl>, total_away_comp_yac_wpa <dbl>,\n# #   total_home_raw_air_wpa <dbl>, total_away_raw_air_wpa <dbl>, total_home_raw_yac_wpa <dbl>,\n# #   ‚Ä¶\n\n\n\nBoom - 1 line of code and we now have a connection - also notice that the output has the following info at the top: > table<pbp_raw_2000-2019> [?? x 291]\nNotice that it has the right number of columns (291) but an unknown number of rows. This is because the data hasn‚Äôt been read into memory yet, and it has only returned the essentially the head() of the data. We don‚Äôt pull the data into memory until we call a new function - collect() this then pulls the data as it is at that point in the pipe into memory.\nQuery the database\nNow let‚Äôs do a basic query - we‚Äôll time it to see how long this takes on all 263 million observations.\n\n\ntic()\npbp_db %>% \n  select(play_type, yards_gained, penalty, season) %>% \n  filter(play_type %in% c(\"run\", \"pass\"), penalty == 0) %>% \n  group_by(season, play_type) %>% \n  summarize(avg_yds = mean(yards_gained, na.rm = TRUE),\n            n = n())\ntoc()\n\n\n\n\n\n# Source:   lazy query [?? x 4]\n# Database: sqlite 3.30.1 [/Users/thomasmock/nflscrapR/data/pbp_db.sqlite]\n# Groups:   season\n#    season play_type avg_yds     n\n#     <dbl> <chr>       <dbl> <int>\n#  1   2000 pass         5.84 17567\n#  2   2000 run          4.08 13682\n#  3   2001 pass         5.85 17264\n#  4   2001 run          4.04 13500\n#  5   2002 pass         5.85 18313\n#  6   2002 run          4.27 13746\n#  7   2003 pass         5.79 17322\n#  8   2003 run          4.24 14033\n#  9   2004 pass         6.12 17238\n# 10   2004 run          4.24 13828\n\n# 1.048 sec elapsed  \n\n\n\nSo we used our traditional dplyr code, it ran as SQL on the backend and took about 1 sec.¬†Now, 1 sec is not THAT fast - and the same operation IN memory would be about 0.2 sec, but we save a lot of time on the read and can do lots of ad-hoc queries without pulling the data in. Also imagine a world where the data is much larger than memory, this same workflow would work on 100 GB of data or even petabytes of data with translation to spark via sparklyr for example.\nCollect the data\nLastly - we can also pull the data into memory, via collect(). This allows us to take the data and either continue to work with the summary or pass it to something like ggplot2.\n\n\ntic()\npbp_db %>% \n  select(play_type, yards_gained, penalty, season) %>% \n  filter(play_type %in% c(\"run\", \"pass\"), penalty == 0) %>% \n  group_by(season, play_type) %>% \n  summarize(avg_yds = mean(yards_gained, na.rm = TRUE),\n            n = n()) %>% \n  collect() %>% \n  ggplot(aes(x = season, y = avg_yds, color = play_type)) +\n  geom_line()\ntoc()\n\n\n\n\n\n# 1.451 sec elapsed  \n\n\n\n\nSo, in about 1.5 seconds we we‚Äôre able to query all of 2000-2019 and get a very basic ggplot. Cool!\nTLDR\nAltogether now skipping the additional info. You can see just how succintly you can use this method. It‚Äôs just like reading in other data formats!\n\n\nlibrary(dplyr)\n\npbp_db <- dplyr::tbl(DBI::dbConnect(RSQLite::SQLite(), \"data/pbp_db.sqlite\"), \"pbp_raw_2000-2019\")\n\npbp_db %>% \n  select(play_type, yards_gained, penalty, season) %>% \n  filter(play_type %in% c(\"run\", \"pass\"), penalty == 0) %>% \n  group_by(season, play_type) %>% \n  summarize(avg_yds = mean(yards_gained, na.rm = TRUE),\n            n = n()) %>% \n  collect()\n\n\n\n\n\n# A tibble: 40 x 4\n# Groups:   season [20]\n#    season play_type avg_yds     n\n#     <dbl> <chr>       <dbl> <int>\n#  1   2000 pass         5.84 17567\n#  2   2000 run          4.08 13682\n#  3   2001 pass         5.85 17264\n#  4   2001 run          4.04 13500\n#  5   2002 pass         5.85 18313\n#  6   2002 run          4.27 13746\n#  7   2003 pass         5.79 17322\n#  8   2003 run          4.24 14033\n#  9   2004 pass         6.12 17238\n# 10   2004 run          4.24 13828\n# ‚Ä¶ with 30 more rows\n\n\n\nAdditional Notes\nI would be remiss to not mention alternative methods to getting relatively normal-sized data into memory. Using R is a great experience for small to medium sized datasets.\ndata.table::fread() is super fast for reading in files\ndata.table is also extremely fast when operating on in-memory data\nJust like with dplyr and dbplyr for reading from databases, dtplyr lets you use dplyr call to run data.table queries ‚Äì I‚Äôll cover this in a follow-up post\n\nvroom::vroom() is even faster for reading in data in some situations\nIn this case for our toy examples, pure dplyr, data.table and dtplyr are all essentially the same speed, about 0.1 - 0.2 seconds to run the same summary in-memory compared to ~ 1 sec via SQLite. However, the time-savings here are very much on read-in. \ndata.table::fread() takes about 28 seconds to read in the full csv, vroom::vroom() takes about 20 seconds to read in the full csv, and then either data.table or dplyr take between 0.1 - 0.2 seconds to perform the aggregation. This is compared to the ~ 1 second to aggregate with the same analysis via dbplyr + RSQLite. \n\n\ntic()\n\ndt_pbp <- fread(\"pbp_large.csv\")\n\ntoc()\n\n\n\n\n\n# |--------------------------------------------------|\n# |==================================================|\n# |--------------------------------------------------|\n# |==================================================|\n\n# 27.875 sec elapsed\n\n\n\nThe last thing I‚Äôll add is that if you want to do additional modeling or work with the entire dataset over a long period of time, I think it makes sense to read it into memory to get the speed improvements of in-memory computation and access to the full range of R‚Äôs capability. Just wanted to bring up that it‚Äôs possible to rapidly work on relatively large datasets and only pull into memory when you are ready. \n\n\n\n",
    "preview": "https://images.unsplash.com/photo-1566577739112-5180d4bf9390?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1526&q=80",
    "last_modified": "2021-03-20T13:32:52+05:30",
    "input_file": {}
  },
  {
    "path": "posts/2020-04-03-beer-and-pdftools-a-vignette/",
    "title": "Beer and pdftools - a vignette",
    "description": "A guide to extracting tables from many PDFs using the pdftools package",
    "author": [
      {
        "name": "Thomas Mock",
        "url": "https://themockup.netlify.com/"
      }
    ],
    "date": "2020-04-04",
    "categories": [],
    "contents": "\nTable of Contents\nScraping Complex Tables from PDFs with PDF ToolsLoad Libraries\n\nPDFsList File Names\n\nRaw PDFsSplit by row\nBuild TableRemove all the extra whitespace\nConvert to tibble\n\n\nAlternative method via readr\nProper CleaningSplit dataframe\nFactor cleaning and final dataframesPrint the dataframes\nFinished Cleaning\n\n\nUse a function\npurrr - iteration without repetitionAll possible combos\nFinal outputManufacture dataset\nMaterial dataset\n\n\nDo it all in 6 Lines of Code!\n\nScraping Complex Tables from PDFs with PDF Tools\nThe goal of this is to provide a guide to extracting irregularly formatted tables from PDFs.\nLoad Libraries\nWe‚Äôll use ROpenSci‚Äôs pdftools package along with several tidyverse packages: - stringr - text manipulation - dplyr - general data manipulation - tidyr - data cleaning - purrr - repeated application of a function\n\n\nlibrary(tidyverse)\nlibrary(pdftools)\n\nPDFs\nThe PDFs for this guide come from Alcohol and Tobacco Tax and Trade Bureau. We‚Äôll use the 2011-2014 data for this example (84 total PDFs). For the purpose of today the files have already been downloaded, but I used the following script.\n\n\n# General function for download\ndownload_monthly_stats_pdf <- function(year){\n  \n  message(paste0(\"Downloading \", year))\n  \n  # The general format is yearmonth like 201101 for Jan 2011.\n  month_in <- c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\")\n  \n  year_vec <- rep(year, 12)\n  \n  url_build <- function(year_vec, month_in){\n      glue::glue(\"https://www.ttb.gov/images/pdfs/statistics/{year}/{year}{month_in}beer.pdf\")\n  }\n  \n  # output to the pdfs folder\n  download_monthly_pdf <- function(year, month, url_in){\n    download.file(\n      url = url_in,\n      destfile = glue::glue(\"pdfs/ttb_monthly_stats_{year}-{month}.pdf\")\n      )\n  }\n  \n  # build all the input urls and attach to an input dataframe\n  full_df <- tibble(year = year_vec, month = month_in) %>% \n    mutate(url_in = pmap_chr(.l = list(year_vec, month_in), .f = url_build)) \n  \n  # The pwalk here takes all 3 inputs and applies them to download_monthly_pdf function\n  pwalk(full_df, .f = download_monthly_pdf)\n  \n}\n\nWe could apply that function to all the years of interest with another purrr::walk() call. This will run download_monthly_stats_pdf() for 2011, 2012, 2013, and 2014.\n\n\nwalk(c(2011:2014), download_monthly_stats_pdf)\n\nList File Names\n\n\n# list all the files we have downloaded so far\nall_files <- list.files(\"pdfs\")\n\nlength(all_files)\n\n[1] 48\n\nWe have 48 PDFs, as expected - 12 months x 4 years = 48!\nNow let‚Äôs take a peek inside one of the PDFs.\n\nRaw PDFs\nWhen we run pdftools::pdf_text() we can see a decently formatted table. The main issue to consider is that there is a lot erroneous header descriptions, and there are unequal spacing between ‚Äúcolumns‚Äù in the table. Importantly, each line of the PDF is separated by a newline \\n. This is key to our strategy for pulling out individual lines.\n\n\npdftools::pdf_text(\"pdfs/ttb_monthly_stats_2011-01.pdf\")\n\n[1] \"                                                                                                                  Report Date:\\n                                              DEPARTMENT OF THE TREASURY                                          30-MAR-2011\\n                                    ALCOHOL AND TOBACCO TAX AND TRADE BUREAU\\n                                                                                                                  Report Symbol:\\n                                                    STATISTICAL REPORT - BEER                                     TTB S 5130-01-2011\\n                                                       Reporting Period: January 2011                             Page: 1 of 1\\n                                                                                                   Current Year         Prior Year\\n                                                                                    Prior Year      Cumulative         Cumulative\\nMANUFACTURE OF BEER                                      Current Month          Current Month      Year to Date        Year to Date\\nProduction                                                    14,981,472               15,012,331     14,981,472           15,012,331\\nRemovals\\nTaxable ($7.00/$18.00 per barrel)\\n   In bottles and cans                                        11,571,819               11,908,922     11,571,819           11,908,922\\n   In barrels and kegs                                          1,245,125                1,245,143      1,245,125            1,245,143\\n   Tax Determined, Premises Use                                     5,989                    5,267          5,989                5,267\\n       Sub Total Taxable                                      12,822,933               13,159,332     12,822,933           13,159,332\\nTax-free\\n   For export                                                     264,669                  224,066        264,669              224,066\\n   For vessels and aircraft                                             0                        0              0                    0\\n   Consumed on brewery premises                                       886                      913            886                  913\\n       Sub Total Tax-Free                                         265,555                  224,979        265,555              224,979\\n   Total Removals                                             13,088,488               13,384,311     13,088,488           13,384,311\\nStocks On Hand end-of-month:                                    9,896,961                9,993,268      9,896,961            9,993,268\\nMATERIALS USED AT BREWERIES\\n   Malt and malt products                                    322,480,722             330,304,432     322,480,722          330,304,432\\n   Corn and corn products                                     58,632,672               56,705,162     58,632,672           56,705,162\\n   Rice and rice products                                    108,112,318               59,701,345    108,112,318           59,701,345\\n   Barley and barley products                                   4,705,175                3,668,374      4,705,175            3,668,374\\n   Wheat and wheat products                                     1,210,137                1,409,685      1,210,137            1,409,685\\n      Total Grain products                                   495,141,024             451,788,998     495,141,024          451,788,998\\n   Sugar and syrups                                           73,793,509               47,308,358     73,793,509           47,308,358\\n   Hops (dry)                                                   6,059,066                4,765,924      6,059,066            4,765,924\\n   Hops (used as extracts)                                        296,605                  271,405        296,605              271,405\\n   Other                                                        7,972,930              10,537,742       7,972,930          10,537,742\\n       Total Non-Grain products                               88,122,110               62,883,429     88,122,110           62,883,429\\nTotal Used                                                   583,263,134             514,672,427     583,263,134          514,672,427\\n         296,605 Pounds of hops is equivalent to           212,541   pounds of extract JAN 2011\\n         271,405 Pounds of hops is equivalent to           101,087   pounds of extract JAN 2010\\nNOTE: Changes in figures from prior reports could be due to amended reports being filed.\\n        This data is not final and may need to be amended.\\nhttp://www.ttb.gov\\n\"\n\nSplit by row\nWe can use stringr::str_split() to separate the text at each of the \\n newlines. This generates a list of character strings, we call unlist() to extract to a vector. We now have a nicely separated vector of character strings, where each row is a new string.\n\n\nraw_text <- pdftools::pdf_text(\"pdfs/ttb_monthly_stats_2011-01.pdf\") %>% \n  str_split(\"\\n\") %>% \n  unlist()\n\nraw_text\n\n [1] \"                                                                                                                  Report Date:\"        \n [2] \"                                              DEPARTMENT OF THE TREASURY                                          30-MAR-2011\"         \n [3] \"                                    ALCOHOL AND TOBACCO TAX AND TRADE BUREAU\"                                                          \n [4] \"                                                                                                                  Report Symbol:\"      \n [5] \"                                                    STATISTICAL REPORT - BEER                                     TTB S 5130-01-2011\"  \n [6] \"                                                       Reporting Period: January 2011                             Page: 1 of 1\"        \n [7] \"                                                                                                   Current Year         Prior Year\"    \n [8] \"                                                                                    Prior Year      Cumulative         Cumulative\"     \n [9] \"MANUFACTURE OF BEER                                      Current Month          Current Month      Year to Date        Year to Date\"   \n[10] \"Production                                                    14,981,472               15,012,331     14,981,472           15,012,331\" \n[11] \"Removals\"                                                                                                                              \n[12] \"Taxable ($7.00/$18.00 per barrel)\"                                                                                                     \n[13] \"   In bottles and cans                                        11,571,819               11,908,922     11,571,819           11,908,922\" \n[14] \"   In barrels and kegs                                          1,245,125                1,245,143      1,245,125            1,245,143\"\n[15] \"   Tax Determined, Premises Use                                     5,989                    5,267          5,989                5,267\"\n[16] \"       Sub Total Taxable                                      12,822,933               13,159,332     12,822,933           13,159,332\" \n[17] \"Tax-free\"                                                                                                                              \n[18] \"   For export                                                     264,669                  224,066        264,669              224,066\"\n[19] \"   For vessels and aircraft                                             0                        0              0                    0\"\n[20] \"   Consumed on brewery premises                                       886                      913            886                  913\"\n[21] \"       Sub Total Tax-Free                                         265,555                  224,979        265,555              224,979\"\n[22] \"   Total Removals                                             13,088,488               13,384,311     13,088,488           13,384,311\" \n[23] \"Stocks On Hand end-of-month:                                    9,896,961                9,993,268      9,896,961            9,993,268\"\n[24] \"MATERIALS USED AT BREWERIES\"                                                                                                           \n[25] \"   Malt and malt products                                    322,480,722             330,304,432     322,480,722          330,304,432\" \n[26] \"   Corn and corn products                                     58,632,672               56,705,162     58,632,672           56,705,162\" \n[27] \"   Rice and rice products                                    108,112,318               59,701,345    108,112,318           59,701,345\" \n[28] \"   Barley and barley products                                   4,705,175                3,668,374      4,705,175            3,668,374\"\n[29] \"   Wheat and wheat products                                     1,210,137                1,409,685      1,210,137            1,409,685\"\n[30] \"      Total Grain products                                   495,141,024             451,788,998     495,141,024          451,788,998\" \n[31] \"   Sugar and syrups                                           73,793,509               47,308,358     73,793,509           47,308,358\" \n[32] \"   Hops (dry)                                                   6,059,066                4,765,924      6,059,066            4,765,924\"\n[33] \"   Hops (used as extracts)                                        296,605                  271,405        296,605              271,405\"\n[34] \"   Other                                                        7,972,930              10,537,742       7,972,930          10,537,742\" \n[35] \"       Total Non-Grain products                               88,122,110               62,883,429     88,122,110           62,883,429\" \n[36] \"Total Used                                                   583,263,134             514,672,427     583,263,134          514,672,427\" \n[37] \"         296,605 Pounds of hops is equivalent to           212,541   pounds of extract JAN 2011\"                                       \n[38] \"         271,405 Pounds of hops is equivalent to           101,087   pounds of extract JAN 2010\"                                       \n[39] \"NOTE: Changes in figures from prior reports could be due to amended reports being filed.\"                                              \n[40] \"        This data is not final and may need to be amended.\"                                                                            \n[41] \"http://www.ttb.gov\"                                                                                                                    \n[42] \"\"                                                                                                                                      \n\nBuild Table\nNow that we have the data split into a vector we can start finding ‚Äúrows‚Äù to drop. We can see that the 9th string is actually the column titles, and the table ends at the 36th string. However, this could change according to which PDF we are looking at, so rather than going by position we can use stringr::str_which() to match a logical with matched text.\n\n\n# Start of table - column names\nraw_text[9]\n\n[1] \"MANUFACTURE OF BEER                                      Current Month          Current Month      Year to Date        Year to Date\"\n\n# End of table - last value\nraw_text[36]\n\n[1] \"Total Used                                                   583,263,134             514,672,427     583,263,134          514,672,427\"\n\nWe get the same ‚Äúrows‚Äù with our matching str_which().\n\n\n# find start of table\nstringr::str_which(raw_text, \"MANUFACTURE OF BEER\")\n\n[1] 9\n\n# find end of table\nstringr::str_which(raw_text, \"Total Used\")\n\n[1] 36\n\nLet‚Äôs actually assign this now, rather than just printing. We can also remove leading/trailing whitespace with stringr::str_trim(). When we look at table_trimmed we can ‚Äúsee‚Äù a group of text strings that much closer resemble a table!\n\n\ntable_start <- stringr::str_which(raw_text, \"MANUFACTURE OF BEER\")\n  \n# End of table (drop all the asterisks and the other descriptors)\ntable_end <- stringr::str_which(raw_text, \"Total Used\")\n  \n# Trim the table to the start/end and drop whitespace at each line\ntable_trimmed <- raw_text[table_start:table_end] %>% \n  str_trim()\n\ntable_trimmed\n\n [1] \"MANUFACTURE OF BEER                                      Current Month          Current Month      Year to Date        Year to Date\"   \n [2] \"Production                                                    14,981,472               15,012,331     14,981,472           15,012,331\" \n [3] \"Removals\"                                                                                                                              \n [4] \"Taxable ($7.00/$18.00 per barrel)\"                                                                                                     \n [5] \"In bottles and cans                                        11,571,819               11,908,922     11,571,819           11,908,922\"    \n [6] \"In barrels and kegs                                          1,245,125                1,245,143      1,245,125            1,245,143\"   \n [7] \"Tax Determined, Premises Use                                     5,989                    5,267          5,989                5,267\"   \n [8] \"Sub Total Taxable                                      12,822,933               13,159,332     12,822,933           13,159,332\"        \n [9] \"Tax-free\"                                                                                                                              \n[10] \"For export                                                     264,669                  224,066        264,669              224,066\"   \n[11] \"For vessels and aircraft                                             0                        0              0                    0\"   \n[12] \"Consumed on brewery premises                                       886                      913            886                  913\"   \n[13] \"Sub Total Tax-Free                                         265,555                  224,979        265,555              224,979\"       \n[14] \"Total Removals                                             13,088,488               13,384,311     13,088,488           13,384,311\"    \n[15] \"Stocks On Hand end-of-month:                                    9,896,961                9,993,268      9,896,961            9,993,268\"\n[16] \"MATERIALS USED AT BREWERIES\"                                                                                                           \n[17] \"Malt and malt products                                    322,480,722             330,304,432     322,480,722          330,304,432\"    \n[18] \"Corn and corn products                                     58,632,672               56,705,162     58,632,672           56,705,162\"    \n[19] \"Rice and rice products                                    108,112,318               59,701,345    108,112,318           59,701,345\"    \n[20] \"Barley and barley products                                   4,705,175                3,668,374      4,705,175            3,668,374\"   \n[21] \"Wheat and wheat products                                     1,210,137                1,409,685      1,210,137            1,409,685\"   \n[22] \"Total Grain products                                   495,141,024             451,788,998     495,141,024          451,788,998\"       \n[23] \"Sugar and syrups                                           73,793,509               47,308,358     73,793,509           47,308,358\"    \n[24] \"Hops (dry)                                                   6,059,066                4,765,924      6,059,066            4,765,924\"   \n[25] \"Hops (used as extracts)                                        296,605                  271,405        296,605              271,405\"   \n[26] \"Other                                                        7,972,930              10,537,742       7,972,930          10,537,742\"    \n[27] \"Total Non-Grain products                               88,122,110               62,883,429     88,122,110           62,883,429\"        \n[28] \"Total Used                                                   583,263,134             514,672,427     583,263,134          514,672,427\" \n\nRemove all the extra whitespace\nNext we need to remove all the huge whitespaces from between columns. The regular expression (regex) of \"\\\\s{2,}\" matches whitespaces of 2 or more. If we use stringr::str_replace_all() to take all the whitespaces > 2 and replace with a new delimiter such as \"|\" we can move to our next step. While we‚Äôre at it, let‚Äôs remove all the commas so that we can go straight to doubles rather than characters for all the beer production variables.\n\n\n# Replace long spaces with a col break symbol\nsquished_table <- str_replace_all(table_trimmed, \"\\\\s{2,}\", \"|\") %>% \n  str_remove_all(\",\")\nsquished_table\n\n [1] \"MANUFACTURE OF BEER|Current Month|Current Month|Year to Date|Year to Date\"\n [2] \"Production|14981472|15012331|14981472|15012331\"                           \n [3] \"Removals\"                                                                 \n [4] \"Taxable ($7.00/$18.00 per barrel)\"                                        \n [5] \"In bottles and cans|11571819|11908922|11571819|11908922\"                  \n [6] \"In barrels and kegs|1245125|1245143|1245125|1245143\"                      \n [7] \"Tax Determined Premises Use|5989|5267|5989|5267\"                          \n [8] \"Sub Total Taxable|12822933|13159332|12822933|13159332\"                    \n [9] \"Tax-free\"                                                                 \n[10] \"For export|264669|224066|264669|224066\"                                   \n[11] \"For vessels and aircraft|0|0|0|0\"                                         \n[12] \"Consumed on brewery premises|886|913|886|913\"                             \n[13] \"Sub Total Tax-Free|265555|224979|265555|224979\"                           \n[14] \"Total Removals|13088488|13384311|13088488|13384311\"                       \n[15] \"Stocks On Hand end-of-month:|9896961|9993268|9896961|9993268\"             \n[16] \"MATERIALS USED AT BREWERIES\"                                              \n[17] \"Malt and malt products|322480722|330304432|322480722|330304432\"           \n[18] \"Corn and corn products|58632672|56705162|58632672|56705162\"               \n[19] \"Rice and rice products|108112318|59701345|108112318|59701345\"             \n[20] \"Barley and barley products|4705175|3668374|4705175|3668374\"               \n[21] \"Wheat and wheat products|1210137|1409685|1210137|1409685\"                 \n[22] \"Total Grain products|495141024|451788998|495141024|451788998\"             \n[23] \"Sugar and syrups|73793509|47308358|73793509|47308358\"                     \n[24] \"Hops (dry)|6059066|4765924|6059066|4765924\"                               \n[25] \"Hops (used as extracts)|296605|271405|296605|271405\"                      \n[26] \"Other|7972930|10537742|7972930|10537742\"                                  \n[27] \"Total Non-Grain products|88122110|62883429|88122110|62883429\"             \n[28] \"Total Used|583263134|514672427|583263134|514672427\"                       \n\nConvert to tibble\nNow we have a nicely formatted vector of strings! We can use tibble::enframe() to create a dataframe/tibble out of the vector.\n\n\n# Convert to tibble\nraw_df <- enframe(squished_table)\n\nraw_df\n\n# A tibble: 28 x 2\n    name value                                                        \n   <int> <chr>                                                        \n 1     1 MANUFACTURE OF BEER|Current Month|Current Month|Year to Date‚Ä¶\n 2     2 Production|14981472|15012331|14981472|15012331               \n 3     3 Removals                                                     \n 4     4 Taxable ($7.00/$18.00 per barrel)                            \n 5     5 In bottles and cans|11571819|11908922|11571819|11908922      \n 6     6 In barrels and kegs|1245125|1245143|1245125|1245143          \n 7     7 Tax Determined Premises Use|5989|5267|5989|5267              \n 8     8 Sub Total Taxable|12822933|13159332|12822933|13159332        \n 9     9 Tax-free                                                     \n10    10 For export|264669|224066|264669|224066                       \n# ‚Ä¶ with 18 more rows\n\nNext we can separate value into the 5 columns. Notice that there are a few ‚Äúrows‚Äù where the data is NA as there were rows that acted only as indicators of the type of beer production. We‚Äôll use them later.\n\n\nyear <- 2011\nmonth <- \"02\"\n\n# Convert to tibble\nbeer_df <- raw_df %>% \n    separate(value, \n             into = c(\"type\", \"month_current\", \"month_prior_year\", \"ytd_current\", \"ytd_prior_year\"), \n             sep = \"\\\\|\") %>% \n  slice(-1) %>% \n  mutate_at(vars(month_current:ytd_prior_year), as.double) %>% \n  mutate(year = as.integer(year), month = as.integer(month)) %>% \n  select(year, month, type, everything())\n\nbeer_df\n\n# A tibble: 27 x 8\n    year month type   name month_current month_prior_year ytd_current\n   <int> <int> <chr> <int>         <dbl>            <dbl>       <dbl>\n 1  2011     2 Prod‚Ä¶     2      14981472         15012331    14981472\n 2  2011     2 Remo‚Ä¶     3            NA               NA          NA\n 3  2011     2 Taxa‚Ä¶     4            NA               NA          NA\n 4  2011     2 In b‚Ä¶     5      11571819         11908922    11571819\n 5  2011     2 In b‚Ä¶     6       1245125          1245143     1245125\n 6  2011     2 Tax ‚Ä¶     7          5989             5267        5989\n 7  2011     2 Sub ‚Ä¶     8      12822933         13159332    12822933\n 8  2011     2 Tax-‚Ä¶     9            NA               NA          NA\n 9  2011     2 For ‚Ä¶    10        264669           224066      264669\n10  2011     2 For ‚Ä¶    11             0                0           0\n# ‚Ä¶ with 17 more rows, and 1 more variable: ytd_prior_year <dbl>\n\nTechnically at this point, we have successfully converted from raw text to a dataframe/table/tibble! HOWEVER, for many many examples in the wild you will need to do additional data cleaning, data manipulation, factor assignment, etc. As such, I‚Äôll continue working on this to get to a final output. I‚Äôll also work on repeating this many times as opposed to one time.\nAlternative method via readr\nThanks to Grant McDermott for bringing up a good point here - I based this method off of tables where the white-space between columns is varying. If the white space is fixed between columns you could skip some steps as seen in the below example using readr::read_fwf(), courtesy of Grant. I believe for most cases either using readr::read_table() or readr::read_fwf() would be simple, but will keep the additional workflow steps in case they help someone down the road!\nOverall, using readr to natively parse the table-format could save the workflow step of trimming, coercing to a tibble, and then separating, and just requires you to indicate the spacing of empty cells either manually with fwf_widths() or guessing/parsing of columns via fwf_empty().\n\n\ntable_start_fwf <- stringr::str_which(raw_text, \"Production\") ## Changed since we're dropping the first row anyway\ntable_end_fwf <- stringr::str_which(raw_text, \"Total Used\")\n\n## Trim the table to the start/end (NB: Don't drop whitespace this time!)\ntable_trimmed_fwf <- raw_text[table_start_fwf:table_end_fwf]\n\nbeer_df_fwf <- read_fwf(table_trimmed_fwf, \n                        fwf_empty(table_trimmed_fwf, \n                                  col_names = c(\"type\", \n                                                \"month_current\", \n                                                \"month_prior_year\", \n                                                \"ytd_current\", \n                                                \"ytd_prior_year\")\n                                  )\n                        )\nbeer_df_fwf\n\n# A tibble: 27 x 5\n   type      month_current month_prior_year ytd_current ytd_prior_year\n   <chr>             <dbl>            <dbl>       <dbl>          <dbl>\n 1 Producti‚Ä¶      14981472         15012331    14981472       15012331\n 2 Removals             NA               NA          NA             NA\n 3 Taxable ‚Ä¶            NA               NA          NA             NA\n 4 In bottl‚Ä¶      11571819         11908922    11571819       11908922\n 5 In barre‚Ä¶       1245125          1245143     1245125        1245143\n 6 Tax Dete‚Ä¶          5989             5267        5989           5267\n 7 Sub Tota‚Ä¶      12822933         13159332    12822933       13159332\n 8 Tax-free             NA               NA          NA             NA\n 9 For expo‚Ä¶        264669           224066      264669         224066\n10 For vess‚Ä¶             0                0           0              0\n# ‚Ä¶ with 17 more rows\n\nOne more alternative would be to just use readr::read_table() or readr::read_table2(). Now in practice this should be fairly robust, and works just fine for the examples here, but for messier tables it may fail which leads to the more complex and longer workflow shown below. Specifically, from the readr::read_table() docs:\n\nread_table() and read_table2() are designed to read the type of textual data where each column is separated by one (or more) > columns of space.\nread_table2() is like read.table(), it allows any number of whitespace characters between columns, and the lines can be of different lengths.\nread_table() is more strict, each line must be the same length, and each field is in the same position in every line. It first finds empty columns and then parses like a fixed width file.\n\n\n\nread_table(raw_text[table_start:table_end], skip =1,\n           col_names = c(\"type\", \"month_current\", \"month_prior_year\", \n                         \"ytd_current\", \"ytd_prior_year\"))\n\n# A tibble: 27 x 5\n   type      month_current month_prior_year ytd_current ytd_prior_year\n   <chr>             <dbl>            <dbl>       <dbl>          <dbl>\n 1 Producti‚Ä¶      14981472         15012331    14981472       15012331\n 2 Removals             NA               NA          NA             NA\n 3 Taxable ‚Ä¶            NA               NA          NA             NA\n 4 In bottl‚Ä¶      11571819         11908922    11571819       11908922\n 5 In barre‚Ä¶       1245125          1245143     1245125        1245143\n 6 Tax Dete‚Ä¶          5989             5267        5989           5267\n 7 Sub Tota‚Ä¶      12822933         13159332    12822933       13159332\n 8 Tax-free             NA               NA          NA             NA\n 9 For expo‚Ä¶        264669           224066      264669         224066\n10 For vess‚Ä¶             0                0           0              0\n# ‚Ä¶ with 17 more rows\n\nProper Cleaning\nThis is actually two datasets that are combined into one large reporting table. As such we need to identify the specific row/point to split the dataset at. We can filter to just the row that matches either the string ‚ÄúMATERIALS USED‚Äù or ‚ÄúIN POUNDS‚Äù, as that indicates a label starting the 2nd dataset.\n\n\nslice_num <- beer_df %>% \n  # find a string that has MATERIALS USED or IN POUNDS\n  # | means OR\n    filter(str_detect(type, \"MATERIALS USED|IN POUNDS\")) %>%\n    pull(name)\n\nslice_num\n\n[1] 16\n\nSplit dataframe\nNext we will add a column based on logic for the slice_num, and assign a grouping variable for either Barrels Produced (dataset 1) or Pounds of Materials Used (dataset 2). We can then drop the unneeded rows with a filter(), group_by() the newly produced grouping variable, and use dplyr::group_split() to separate the combined dataset into a list of both datasets.\n\n\n# split data into materials vs barrels produced\nsplit_df <- beer_df %>% \n  mutate(data_type = ifelse(name >= slice_num, \"Pounds of Materials Used\", \"Barrels Produced\"),\n         type = str_remove(type, \":\")) %>% \n  select(data_type, everything(), -name) %>% \n  filter(!str_detect(type, \"IN POUNDS|MATERIALS USED|MANUFACTURE OF BEER|BARRELS\")) %>% \n  group_by(data_type) %>% \n  group_split()\n\nglimpse(split_df)\n\nlist<df[,8]> [1:2] \n$ : tibble [14 √ó 8] (S3: tbl_df/tbl/data.frame)\n$ : tibble [12 √ó 8] (S3: tbl_df/tbl/data.frame)\n@ ptype: tibble [0 √ó 8] (S3: tbl_df/tbl/data.frame)\n\nFactor cleaning and final dataframes\nWe can see that the split_df object is a list of 2 tibbles/dataframes. We can now operate on the individual dataframes and finalize the factor cleaning and assignment to make the data a bit tidier and analysis ready.\n\n\nmanufacture_df <- split_df[[1]] %>% \n  mutate(\n    tax_status = case_when(\n      type %in% c(\"In bottles and cans\", \"In kegs\", \"In barrels and kegs\",\n                  \"Tax Determined, Premises Use\") ~ \"Taxable\",\n      type == \"Sub Total Taxable\" ~ \"Sub Total Taxable\",\n      type %in% c(\"For export\", \"For vessels and aircraft\", \n                  \"Consumed on brewery premises\") ~ \"Tax Free\",\n      type == \"Sub Total Tax-Free\" ~ \"Sub Total Tax-Free\",\n      type %in% c(\"Production\", \"Total Removals\", \n                  \"Stocks On Hand end-of-month:\") ~ \"Totals\"\n      ),\n    tax_rate = dplyr::if_else(year <= 2017, \"$7/$18 per barrel\", \"$3.50/$16 per barrel\")\n    ) %>% \n  filter(!is.na(tax_status)) %>% \n  select(data_type, tax_status, everything())\n\n\n\n# clean up the material dataset\nmaterial_df <- split_df[[2]] %>% \n  mutate(\n    material_type = case_when(\n      str_detect(type, \"Malt|Corn|Rice|Barley|Wheat\") ~ \"Grain Products\",\n      str_detect(type, \"Sugar|Hops|Other\") ~ \"Non-Grain Products\",\n      str_detect(type, \"Total\") ~ type\n    )\n  ) %>% \n  select(data_type, material_type, everything())\n\nPrint the dataframes\nThe manufacture dataframe now has the labels, factors, etc separated into nice columns, with the 4x columns for specific barrels produced.\n\n\nmanufacture_df\n\n# A tibble: 9 x 10\n  data_type tax_status  year month type  month_current\n  <chr>     <chr>      <int> <int> <chr>         <dbl>\n1 Barrels ‚Ä¶ Totals      2011     2 Prod‚Ä¶      14981472\n2 Barrels ‚Ä¶ Taxable     2011     2 In b‚Ä¶      11571819\n3 Barrels ‚Ä¶ Taxable     2011     2 In b‚Ä¶       1245125\n4 Barrels ‚Ä¶ Sub Total‚Ä¶  2011     2 Sub ‚Ä¶      12822933\n5 Barrels ‚Ä¶ Tax Free    2011     2 For ‚Ä¶        264669\n6 Barrels ‚Ä¶ Tax Free    2011     2 For ‚Ä¶             0\n7 Barrels ‚Ä¶ Tax Free    2011     2 Cons‚Ä¶           886\n8 Barrels ‚Ä¶ Sub Total‚Ä¶  2011     2 Sub ‚Ä¶        265555\n9 Barrels ‚Ä¶ Totals      2011     2 Tota‚Ä¶      13088488\n# ‚Ä¶ with 4 more variables: month_prior_year <dbl>, ytd_current <dbl>,\n#   ytd_prior_year <dbl>, tax_rate <chr>\n\nThe material dataframe now has the labels, factors, etc separated into nice columns, with the 4x columns for specific pounds of product used.\n\n\nmaterial_df\n\n# A tibble: 12 x 9\n   data_type material_type  year month type  month_current\n   <chr>     <chr>         <int> <int> <chr>         <dbl>\n 1 Pounds o‚Ä¶ Grain Produc‚Ä¶  2011     2 Malt‚Ä¶     322480722\n 2 Pounds o‚Ä¶ Grain Produc‚Ä¶  2011     2 Corn‚Ä¶      58632672\n 3 Pounds o‚Ä¶ Grain Produc‚Ä¶  2011     2 Rice‚Ä¶     108112318\n 4 Pounds o‚Ä¶ Grain Produc‚Ä¶  2011     2 Barl‚Ä¶       4705175\n 5 Pounds o‚Ä¶ Grain Produc‚Ä¶  2011     2 Whea‚Ä¶       1210137\n 6 Pounds o‚Ä¶ Total Grain ‚Ä¶  2011     2 Tota‚Ä¶     495141024\n 7 Pounds o‚Ä¶ Non-Grain Pr‚Ä¶  2011     2 Suga‚Ä¶      73793509\n 8 Pounds o‚Ä¶ Non-Grain Pr‚Ä¶  2011     2 Hops‚Ä¶       6059066\n 9 Pounds o‚Ä¶ Non-Grain Pr‚Ä¶  2011     2 Hops‚Ä¶        296605\n10 Pounds o‚Ä¶ Non-Grain Pr‚Ä¶  2011     2 Other       7972930\n11 Pounds o‚Ä¶ Total Non-Gr‚Ä¶  2011     2 Tota‚Ä¶      88122110\n12 Pounds o‚Ä¶ Total Used     2011     2 Tota‚Ä¶     583263134\n# ‚Ä¶ with 3 more variables: month_prior_year <dbl>, ytd_current <dbl>,\n#   ytd_prior_year <dbl>\n\nFinished Cleaning\nWe have now finished cleaning the manufacting and material dataframes! However, we did this all line-by-line without functions and would need to repeat this for the other 47 PDFs! Let‚Äôs convert ALL that code into a function that outputs the final dataframes.\nUse a function\n\n\n# create a function that works for most years\nget_beer_tables <- function(year, month) {\n  \n  # read in the raw PDF\n  raw_text <- pdftools::pdf_text(glue::glue(\"pdfs/ttb_monthly_stats_{year}-{month}.pdf\")) %>%\n    str_split(\"\\n\") %>%\n    unlist()\n\n  ## Build Table\n\n  # find start of table\n  table_start <- stringr::str_which(raw_text, \"MANUFACTURE OF BEER\")\n\n  # End of table (drop all the asterisks and the other descriptors)\n  table_end <- stringr::str_which(raw_text, \"Total Used\")\n\n  # Trim the table to the start/end and drop whitespace at each line\n  table_trimmed <- raw_text[table_start:table_end] %>%\n    str_trim()\n\n  table_trimmed\n\n  ### Remove all the extra whitespace\n\n  # Replace long spaces with a col break symbol\n  squished_table <- str_replace_all(table_trimmed, \"\\\\s{2,}\", \"|\") %>%\n    str_remove_all(\",\")\n\n  ### Convert to tibble\n\n  # Convert to tibble\n  raw_df <- enframe(squished_table)\n  \n  # split the rows into their columns\n  beer_df <- suppressWarnings(raw_df %>%\n    separate(value,\n      into = c(\"type\", \"month_current\", \"month_prior_year\", \"ytd_current\", \"ytd_prior_year\"),\n      sep = \"\\\\|\"\n    ) %>%\n    slice(-1) %>%\n    mutate_at(vars(month_current:ytd_prior_year), as.double) %>%\n    mutate(year = as.integer(year), month = as.integer(month)) %>%\n    select(year, month, type, everything()))\n\n  ### Proper Cleaning\n\n  # ID the specific row/point to split the dataset at.\n\n  slice_num <- beer_df %>%\n    # find a string that has MATERIALS USED or IN POUNDS\n    # | means OR\n    filter(str_detect(type, \"MATERIALS USED|IN POUNDS\")) %>%\n    pull(name)\n\n  #### Split dataframe\n\n  # split data into materials vs barrels produced\n  split_df <- suppressWarnings(beer_df %>%\n    mutate(\n      data_type = ifelse(name >= slice_num, \"Pounds of Materials Used\", \"Barrels Produced\"),\n      type = str_remove(type, \":\")\n    ) %>%\n    select(data_type, everything(), -name) %>%\n    filter(!str_detect(type, \"IN POUNDS|MATERIALS USED|MANUFACTURE OF BEER|BARRELS\")) %>%\n    group_by(data_type) %>%\n    group_split())\n\n  #### Factor cleaning and final dataframes\n\n  # clean manufacture df\n  manufacture_df <- split_df[[1]] %>%\n    mutate(\n      tax_status = case_when(\n        type %in% c(\n          \"In bottles and cans\", \"In kegs\", \"In barrels and kegs\",\n          \"Tax Determined, Premises Use\"\n        ) ~ \"Taxable\",\n        type == \"Sub Total Taxable\" ~ \"Sub Total Taxable\",\n        type %in% c(\n          \"For export\", \"For vessels and aircraft\",\n          \"Consumed on brewery premises\"\n        ) ~ \"Tax Free\",\n        type == \"Sub Total Tax-Free\" ~ \"Sub Total Tax-Free\",\n        type %in% c(\n          \"Production\", \"Total Removals\",\n          \"Stocks On Hand end-of-month:\"\n        ) ~ \"Totals\"\n      ),\n      tax_rate = dplyr::if_else(year <= 2017, \"$7/$18 per barrel\", \"$3.50/$16 per barrel\")\n    ) %>%\n    filter(!is.na(tax_status)) %>%\n    select(data_type, tax_status, everything())\n\n  # clean up the material dataset\n  material_df <- split_df[[2]] %>%\n    mutate(\n      material_type = case_when(\n        str_detect(type, \"Malt|Corn|Rice|Barley|Wheat\") ~ \"Grain Products\",\n        str_detect(type, \"Sugar|Hops|Other\") ~ \"Non-Grain Products\",\n        str_detect(type, \"Total\") ~ type\n      )\n    ) %>%\n    select(data_type, material_type, everything())\n\n  # output a list of both dfs\n  list(manufacture_df, material_df)\n}\n\nReally the only code we have changed is we added a glue call to add the year, month to which PDF to read in, and we have the output as a list of both dataframes. Let‚Äôs test our function!\n\n\nget_beer_tables(2011, \"01\")\n\n[[1]]\n# A tibble: 9 x 10\n  data_type tax_status  year month type  month_current\n  <chr>     <chr>      <int> <int> <chr>         <dbl>\n1 Barrels ‚Ä¶ Totals      2011     1 Prod‚Ä¶      14981472\n2 Barrels ‚Ä¶ Taxable     2011     1 In b‚Ä¶      11571819\n3 Barrels ‚Ä¶ Taxable     2011     1 In b‚Ä¶       1245125\n4 Barrels ‚Ä¶ Sub Total‚Ä¶  2011     1 Sub ‚Ä¶      12822933\n5 Barrels ‚Ä¶ Tax Free    2011     1 For ‚Ä¶        264669\n6 Barrels ‚Ä¶ Tax Free    2011     1 For ‚Ä¶             0\n7 Barrels ‚Ä¶ Tax Free    2011     1 Cons‚Ä¶           886\n8 Barrels ‚Ä¶ Sub Total‚Ä¶  2011     1 Sub ‚Ä¶        265555\n9 Barrels ‚Ä¶ Totals      2011     1 Tota‚Ä¶      13088488\n# ‚Ä¶ with 4 more variables: month_prior_year <dbl>, ytd_current <dbl>,\n#   ytd_prior_year <dbl>, tax_rate <chr>\n\n[[2]]\n# A tibble: 12 x 9\n   data_type material_type  year month type  month_current\n   <chr>     <chr>         <int> <int> <chr>         <dbl>\n 1 Pounds o‚Ä¶ Grain Produc‚Ä¶  2011     1 Malt‚Ä¶     322480722\n 2 Pounds o‚Ä¶ Grain Produc‚Ä¶  2011     1 Corn‚Ä¶      58632672\n 3 Pounds o‚Ä¶ Grain Produc‚Ä¶  2011     1 Rice‚Ä¶     108112318\n 4 Pounds o‚Ä¶ Grain Produc‚Ä¶  2011     1 Barl‚Ä¶       4705175\n 5 Pounds o‚Ä¶ Grain Produc‚Ä¶  2011     1 Whea‚Ä¶       1210137\n 6 Pounds o‚Ä¶ Total Grain ‚Ä¶  2011     1 Tota‚Ä¶     495141024\n 7 Pounds o‚Ä¶ Non-Grain Pr‚Ä¶  2011     1 Suga‚Ä¶      73793509\n 8 Pounds o‚Ä¶ Non-Grain Pr‚Ä¶  2011     1 Hops‚Ä¶       6059066\n 9 Pounds o‚Ä¶ Non-Grain Pr‚Ä¶  2011     1 Hops‚Ä¶        296605\n10 Pounds o‚Ä¶ Non-Grain Pr‚Ä¶  2011     1 Other       7972930\n11 Pounds o‚Ä¶ Total Non-Gr‚Ä¶  2011     1 Tota‚Ä¶      88122110\n12 Pounds o‚Ä¶ Total Used     2011     1 Tota‚Ä¶     583263134\n# ‚Ä¶ with 3 more variables: month_prior_year <dbl>, ytd_current <dbl>,\n#   ytd_prior_year <dbl>\n\nBoom! Function is working for our example, let‚Äôs try it out with more than 1 input via purrr!\npurrr - iteration without repetition\nWe‚Äôll be using pmap() to apply our function multiple times, where pmap can take any number of inputs. For example if we call get_beer_tables() via pmap, we can get our tables for that 1 year/month combo!\n\n\n# Quick test of purrr\npmap(list(2011, \"02\"), get_beer_tables)\n\n[[1]]\n[[1]][[1]]\n# A tibble: 9 x 10\n  data_type tax_status  year month type  month_current\n  <chr>     <chr>      <int> <int> <chr>         <dbl>\n1 Barrels ‚Ä¶ Totals      2011     2 Prod‚Ä¶      14350832\n2 Barrels ‚Ä¶ Taxable     2011     2 In b‚Ä¶      11509264\n3 Barrels ‚Ä¶ Taxable     2011     2 In b‚Ä¶       1234147\n4 Barrels ‚Ä¶ Sub Total‚Ä¶  2011     2 Sub ‚Ä¶      12749447\n5 Barrels ‚Ä¶ Tax Free    2011     2 For ‚Ä¶        279150\n6 Barrels ‚Ä¶ Tax Free    2011     2 For ‚Ä¶             0\n7 Barrels ‚Ä¶ Tax Free    2011     2 Cons‚Ä¶           942\n8 Barrels ‚Ä¶ Sub Total‚Ä¶  2011     2 Sub ‚Ä¶        280092\n9 Barrels ‚Ä¶ Totals      2011     2 Tota‚Ä¶      13029539\n# ‚Ä¶ with 4 more variables: month_prior_year <dbl>, ytd_current <dbl>,\n#   ytd_prior_year <dbl>, tax_rate <chr>\n\n[[1]][[2]]\n# A tibble: 12 x 9\n   data_type material_type  year month type  month_current\n   <chr>     <chr>         <int> <int> <chr>         <dbl>\n 1 Pounds o‚Ä¶ Grain Produc‚Ä¶  2011     2 Malt‚Ä¶     307076591\n 2 Pounds o‚Ä¶ Grain Produc‚Ä¶  2011     2 Corn‚Ä¶      53981943\n 3 Pounds o‚Ä¶ Grain Produc‚Ä¶  2011     2 Rice‚Ä¶      54287863\n 4 Pounds o‚Ä¶ Grain Produc‚Ä¶  2011     2 Barl‚Ä¶       4322047\n 5 Pounds o‚Ä¶ Grain Produc‚Ä¶  2011     2 Whea‚Ä¶        955671\n 6 Pounds o‚Ä¶ Total Grain ‚Ä¶  2011     2 Tota‚Ä¶     420624115\n 7 Pounds o‚Ä¶ Non-Grain Pr‚Ä¶  2011     2 Suga‚Ä¶      63374850\n 8 Pounds o‚Ä¶ Non-Grain Pr‚Ä¶  2011     2 Hops‚Ä¶       7617974\n 9 Pounds o‚Ä¶ Non-Grain Pr‚Ä¶  2011     2 Hops‚Ä¶        275963\n10 Pounds o‚Ä¶ Non-Grain Pr‚Ä¶  2011     2 Other       7997916\n11 Pounds o‚Ä¶ Total Non-Gr‚Ä¶  2011     2 Tota‚Ä¶      79266703\n12 Pounds o‚Ä¶ Total Used     2011     2 Tota‚Ä¶     499890818\n# ‚Ä¶ with 3 more variables: month_prior_year <dbl>, ytd_current <dbl>,\n#   ytd_prior_year <dbl>\n\nHowever our goal is all the inputs at once! We can create a vector of the month inputs as character strings, and then use tidyr::crossing() to output all the possible combinations of year + month as a dataframe. Notice two columns, year and month with a length of 48 - equal to all of our PDFs!\n\n\n# add the month_num as vector\nmonth_num <- c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\")\n\n# use crossing to generate all combos for the data \n# 2010 is missing, but as the data has prior year data we can theoretically\n# add it back in after the fact\n\ncrossing(\n  year = c(2011:2014), \n  month = month_num\n  ) %>% glimpse()\n\nRows: 48\nColumns: 2\n$ year  <int> 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011,‚Ä¶\n$ month <chr> \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\",‚Ä¶\n\nAll possible combos\nWe can use tidyr::crossing() again to generate the possible inputs and create the output dataframes as list column of two dataframes. Running this takes only about 2 seconds across the 48 PDFs! The output is not very exciting as the data is simply the year & month columns, plus a list-column called data. Let‚Äôs get the final outputs!\n\n\n# add the month_num as vector\nmonth_num <- c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\")\n\n# use crossing to generate all combos for the data \ndf_2011_2014 <- crossing(year = c(2011:2014), \n                         month = month_num) %>% \n  mutate(data = pmap(., get_beer_tables))\n\ndf_2011_2014\n\n# A tibble: 48 x 3\n    year month data      \n   <int> <chr> <list>    \n 1  2011 01    <list [2]>\n 2  2011 02    <list [2]>\n 3  2011 03    <list [2]>\n 4  2011 04    <list [2]>\n 5  2011 05    <list [2]>\n 6  2011 06    <list [2]>\n 7  2011 07    <list [2]>\n 8  2011 08    <list [2]>\n 9  2011 09    <list [2]>\n10  2011 10    <list [2]>\n# ‚Ä¶ with 38 more rows\n\nFinal output\nWe can now get just the output data, drop the other columns. We‚Äôre still working with list-columns, so let‚Äôs get to the manufacture_df and material_df.\n\n\nfinal_output <- df_2011_2014 %>%\n  # grab the data into respective columns\n  mutate(manufacture_data = map(data, 1),\n         material_data = map(data, 2)) %>% \n  select(manufacture_data, material_data)\n\nfinal_output\n\n# A tibble: 48 x 2\n   manufacture_data  material_data    \n   <list>            <list>           \n 1 <tibble [9 √ó 10]> <tibble [12 √ó 9]>\n 2 <tibble [9 √ó 10]> <tibble [12 √ó 9]>\n 3 <tibble [9 √ó 10]> <tibble [12 √ó 9]>\n 4 <tibble [9 √ó 10]> <tibble [12 √ó 9]>\n 5 <tibble [9 √ó 10]> <tibble [12 √ó 9]>\n 6 <tibble [9 √ó 10]> <tibble [12 √ó 9]>\n 7 <tibble [9 √ó 10]> <tibble [12 √ó 9]>\n 8 <tibble [9 √ó 10]> <tibble [12 √ó 9]>\n 9 <tibble [9 √ó 10]> <tibble [12 √ó 9]>\n10 <tibble [9 √ó 10]> <tibble [12 √ó 9]>\n# ‚Ä¶ with 38 more rows\n\nThe manufacture dataframe can be combined as below.\n\n\n# Grab just the manufacture data\nmanufacture_df <- final_output %>% \n  select(manufacture_data) %>% \n  unnest(manufacture_data)\n\n# Grab just the manufacture data\nmaterial_df <- final_output %>% \n  select(material_data) %>% \n  unnest(material_data)\n\nAnd now we can look at the outputs!\nManufacture dataset\n\n\nglimpse(manufacture_df)\n\nRows: 432\nColumns: 10\n$ data_type        <chr> \"Barrels Produced\", \"Barrels Produced\", \"B‚Ä¶\n$ tax_status       <chr> \"Totals\", \"Taxable\", \"Taxable\", \"Sub Total‚Ä¶\n$ year             <int> 2011, 2011, 2011, 2011, 2011, 2011, 2011, ‚Ä¶\n$ month            <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, ‚Ä¶\n$ type             <chr> \"Production\", \"In bottles and cans\", \"In b‚Ä¶\n$ month_current    <dbl> 14981472, 11571819, 1245125, 12822933, 264‚Ä¶\n$ month_prior_year <dbl> 15012331, 11908922, 1245143, 13159332, 224‚Ä¶\n$ ytd_current      <dbl> 14981472, 11571819, 1245125, 12822933, 264‚Ä¶\n$ ytd_prior_year   <dbl> 15012331, 11908922, 1245143, 13159332, 224‚Ä¶\n$ tax_rate         <chr> \"$7/$18 per barrel\", \"$7/$18 per barrel\", ‚Ä¶\n\nMaterial dataset\n\n\nglimpse(material_df)\n\nRows: 576\nColumns: 9\n$ data_type        <chr> \"Pounds of Materials Used\", \"Pounds of Mat‚Ä¶\n$ material_type    <chr> \"Grain Products\", \"Grain Products\", \"Grain‚Ä¶\n$ year             <int> 2011, 2011, 2011, 2011, 2011, 2011, 2011, ‚Ä¶\n$ month            <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, ‚Ä¶\n$ type             <chr> \"Malt and malt products\", \"Corn and corn p‚Ä¶\n$ month_current    <dbl> 322480722, 58632672, 108112318, 4705175, 1‚Ä¶\n$ month_prior_year <dbl> 330304432, 56705162, 59701345, 3668374, 14‚Ä¶\n$ ytd_current      <dbl> 322480722, 58632672, 108112318, 4705175, 1‚Ä¶\n$ ytd_prior_year   <dbl> 330304432, 56705162, 59701345, 3668374, 14‚Ä¶\n\nDo it all in 6 Lines of Code!\nNow all of that could have been done in about 6 lines of tidyverse code since we created a function.\n\n\n# Use crossing to generate all 48 combos for the data \n# Use purrr to read in, clean, and output the 96 tables from the 48 PDFs\nfinal_output <- crossing(year = c(2011:2014), month = month_num) %>% \n  mutate(data = pmap(., get_beer_tables)) %>% \n  mutate(manufacture_data = map(data, 1), material_data = map(data, 2)) %>% \n  select(manufacture_data, material_data)\n\n# Grab just the manufacture data\nmanufacture_df <- final_output %>% select(manufacture_data) %>% unnest(manufacture_data)\n\n# Grab just the manufacture data\nmaterial_df <- final_output %>% select(material_data) %>% unnest(material_data)\n\n\n\n",
    "preview": "posts/2020-04-03-beer-and-pdftools-a-vignette/beer-kegs.jpeg",
    "last_modified": "2021-03-20T13:32:52+05:30",
    "input_file": {}
  },
  {
    "path": "posts/2019-01-09-add-a-logo-to-your-plot/",
    "title": "Add a logo to your plot",
    "description": "Put a bird on it - Portlandia.",
    "author": [
      {
        "name": "Thomas Mock",
        "url": {}
      }
    ],
    "date": "2019-01-09",
    "categories": [
      "magick",
      "data visualization",
      "ggplot2"
    ],
    "contents": "\n\nContents\nMagic with magick!\nBuilding a ggplot with a logo\nRead in a plot\nWhere to put the logo?\nAdd the logo\nPut it in a function! (Bird not included)\nThe function details\n\n\n\n\n\nvia GIPHY\n\nIf you missed out on Portlandia, you should take some time to watch this clip of the ‚ÄúPut a bird on it‚Äù episode.\n\n\nJust like Bryce and Lisa - we can put birds on anything with the magick package from ROpenSci!\nSo let‚Äôs get started putting birds on things!\nMagic with magick!\nThe magick package is an R interface to the ImageMagick STL, one of the most comprehensive open source image processing libraries. It gives a lot of power to R users, and we‚Äôll briefly cover the workflow before getting into our real example.\nIf you want a deeper dive on all the features of magick, check out their awesome vignette!\n\n\n# Load the library\nlibrary(magick)\n\n# \"read\" in an image\ndog <- image_read(\"https://images.pexels.com/photos/1564506/pexels-photo-1564506.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=650&w=940\")\n\nimage_info(dog)\n\n\n  format width height colorspace matte filesize density\n1   JPEG  1880   1208       sRGB FALSE    87114   72x72\n\nWe can see a few things about the r_logo object, it is a .png, it‚Äôs height and width, filesize, and DPI/density.\nWe can also view the image in line.\n\n\nprint(dog)\n\n\n  format width height colorspace matte filesize density\n1   JPEG  1880   1208       sRGB FALSE    87114   72x72\n\n\nWe also have image manipulation options like image_rotate, image_resize, all of which are pipeable with the %>%.\n\n\ndog %>% \n  image_rotate(30) %>% # rotate 30 degrees\n  image_resize(\"400x400\") %>%  # change size to 400 x 400 pixels\n  image_flop() # flip the image horizontally\n\n\n\n\nMost importantly we can put a bird on it!\n\n\nbird <- image_read(\"https://user-images.githubusercontent.com/29187501/38769895-edae85d0-3fcf-11e8-95f9-bbd530b32771.png\") %>% \n  image_resize(\"150x150\")\n\nimage_composite(dog, bird)\n\n\n\n\nNow please note where the bird showed up, in the top left corner. We can control the placement of composite images by specifying the offset.\n\n\ndog %>% \n  image_composite(bird, offset = \"+500+1000\")\n\n\n\n\nNotice that offset reads as x-axis pixels, y-axis pixels, so \"+500+1000 indicates from the top left corner place the image 500 pixels to the right and 1000 pixels down.\nNow that we‚Äôve been oriented to how the magick package works, and had some fun by putting a bird on our lovely Boston Terrier model, let‚Äôs dive into the real purpose of this post - adding a logo to your ggplot!\nBuilding a ggplot with a logo\nIn the exampe I will show below you will have already saved the plot as an image, so we can skip with the normal ggplot2 code. However, please note that if you do want to build in some extra whitespace to your plot to save ‚Äúspace‚Äù for your logo you can do so by changing the margins of your overall plot. You can also add a figure caption with labs(caption = \"text to change here\"), which inherently adds some whitespace to incorporate the caption.\nMargins can take multiple units arguments including: ‚Äúcm‚Äù, ‚Äúin‚Äù, ‚Äúlines‚Äù, ‚Äúpt‚Äù, for more info check out the ggplot2 docs.\nNotice: The margins read as t, r, b, l or c(top, right, bottom, left). I typically see logos on the bottom left or top right so you can:\nadd space at the top for example with:c(2.5, 0.5, 0.5, 0.5)\nadd space to the bottom with:c(0.5, 0.5, 2.5, 0.5)\nNotice the below plot has extra space on the bottom, and I have added a grey background purely to highlight this extra space.\n\n\nlibrary(tidyverse)\n\nmtcars %>% \n  ggplot(aes(x = cyl, y = mpg)) +\n  geom_point() +\n  theme(plot.margin = unit(c(0.5, 0.5, 2.5, 0.5), \"lines\"),\n        plot.background = element_rect(\"lightgrey\"))\n\n\n\n# plot background = lightgrey for highlight, not necessary for sizing\n\n\n\nRead in a plot\nSo let‚Äôs read in our publication plot to work with! Please notice that this can be a local file with traditional path structure or a hosted image as a url. I‚Äôm using URLs so you can try these out yourself!\n\n\npub_plot <- image_read(\"https://raw.githubusercontent.com/jthomasmock/tomtom/master/vignettes/basic_plot.png\")\n\nlogo <- image_read(\"https://www.rstudio.com/wp-content/uploads/2018/10/RStudio-Logo-Flat.png\") %>% \n  image_resize(300)\n\nprint(pub_plot)\n\n\n# A tibble: 1 x 7\n  format width height colorspace matte filesize density\n  <chr>  <int>  <int> <chr>      <lgl>    <int> <chr>  \n1 PNG     2222   1951 sRGB       TRUE    168897 72x72  \n\nprint(logo)\n\n\n# A tibble: 1 x 7\n  format width height colorspace matte filesize density\n  <chr>  <int>  <int> <chr>      <lgl>    <int> <chr>  \n1 PNG      300    105 sRGB       TRUE         0 57x57  \n\n\nWhere to put the logo?\nWe can then overlay the logo over the plot, let‚Äôs try bottom left, and we want ~ 1% padding for aesthetics - so we can use the following code to get dimensions and pixel numbers.\n\n\n# get dims of the plot\nplot_height <- magick::image_info(pub_plot)$height\nplot_width <- magick::image_info(pub_plot)$width\n\n# get dims of the logo\nlogo_width <- magick::image_info(logo)$width\nlogo_height <- magick::image_info(logo)$height\n\n# get number of pixels to be 1% from the bottom of the plot\n# while accounting for the logo height\nplot_height - logo_height - plot_height * 0.01\n\n\n[1] 1826.49\n\n# get number of pixels to be 1% from the left of the plot\nplot_width * 0.01\n\n\n[1] 22.22\n\nAdd the logo\nBy using offset = \"+22+1826\" we indicate that we are placing the logo 22 pixels to the right and 1826 pixels down.\n\n\npub_plot %>% \n  image_composite(logo, offset = \"+22+1826\")\n\n\n\n\nBoom! We have our logo overlay on the plot in the right location! But we had to manually figure out and set the logo position, which is less than ideal for programmatic use down the road. I also manually resized the logo to 300 pixels in an earlier step - we should make that automagick as well!\nPut it in a function! (Bird not included)\nTo make the logo add process more reproducible, we can build a function to take the various heights and widths of the logo/plot and automatically resize the logo to match as well as calculating the number of pixels to put it in each respective corner. The logo_scale argument defaults to 10 - so the logo will be 1/10th the width of the plot.\n\n\nplot_with_logo <- add_logo(\n  plot_path = \"\", # url or local file for the plot\n  logo_path = \"\", # url or local file for the logo\n  logo_position = \"\" # choose a corner\n  # 'top left', 'top right', 'bottom left' or 'bottom right'\n  #logo_scale = 10 as default, but can change to manually make logo bigger\n)\n\n# save the image and write to working directory\nmagick::image_write(plot_with_logo, \"plot_with_logo.png\")\n\n\n\nThe function details\nThis function takes in two images, gets the dimension information, then pastes the logo at 1/10th scale in the specified corner with 1% padding. The function also has a warning if you input a logo_position that is not included.\n\n\nadd_logo <- function(plot_path, logo_path, logo_position, logo_scale = 10){\n\n    # Requires magick R Package https://github.com/ropensci/magick\n\n    # Useful error message for logo position\n    if (!logo_position %in% c(\"top right\", \"top left\", \"bottom right\", \"bottom left\")) {\n        stop(\"Error Message: Uh oh! Logo Position not recognized\\n  Try: logo_positon = 'top left', 'top right', 'bottom left', or 'bottom right'\")\n    }\n\n    # read in raw images\n    plot <- magick::image_read(plot_path)\n    logo_raw <- magick::image_read(logo_path)\n\n    # get dimensions of plot for scaling\n    plot_height <- magick::image_info(plot)$height\n    plot_width <- magick::image_info(plot)$width\n\n    # default scale to 1/10th width of plot\n    # Can change with logo_scale\n    logo <- magick::image_scale(logo_raw, as.character(plot_width/logo_scale))\n\n    # Get width of logo\n    logo_width <- magick::image_info(logo)$width\n    logo_height <- magick::image_info(logo)$height\n\n    # Set position of logo\n    # Position starts at 0,0 at top left\n    # Using 0.01 for 1% - aesthetic padding\n\n    if (logo_position == \"top right\") {\n        x_pos = plot_width - logo_width - 0.01 * plot_width\n        y_pos = 0.01 * plot_height\n    } else if (logo_position == \"top left\") {\n        x_pos = 0.01 * plot_width\n        y_pos = 0.01 * plot_height\n    } else if (logo_position == \"bottom right\") {\n        x_pos = plot_width - logo_width - 0.01 * plot_width\n        y_pos = plot_height - logo_height - 0.01 * plot_height\n    } else if (logo_position == \"bottom left\") {\n        x_pos = 0.01 * plot_width\n        y_pos = plot_height - logo_height - 0.01 * plot_height\n    }\n\n    # Compose the actual overlay\n    magick::image_composite(plot, logo, offset = paste0(\"+\", x_pos, \"+\", y_pos))\n\n}\n\n\n\n\n\n\nSo there you go! Happy logo adding and bird putting!\nFor more information on adding logos to plots with magick::image_append() instead, check out this blog post by Daniel Hadley on using magick::image_append to add a logo or his RStudioConf talk on the same idea.\nCheers!\n\n\n\n\n",
    "preview": "https://images.pexels.com/photos/1564506/pexels-photo-1564506.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=650&w=940",
    "last_modified": "2021-03-20T13:32:52+05:30",
    "input_file": {}
  },
  {
    "path": "posts/2019-01-02-tidytuesday-enhancements/",
    "title": "TidyTuesday enhancements",
    "description": "Making #TidyTuesday better.",
    "author": [
      {
        "name": "Thomas Mock",
        "url": {}
      }
    ],
    "date": "2019-01-02",
    "categories": [
      "TidyTuesday",
      "tidyverse",
      "Automation"
    ],
    "contents": "\n\n\n\n\nOne of my #rstats goals for 2019 was to make #TidyTuesday better, both from the experience on GitHub and the weekly posting for myself and for others.\nThe first thing I did for the project was to re-organize the GitHub repo, moving all the 2018 data into an archived folder and making a new 2019 folder to begin populating with new data! Additionally, with some help from Philip Khor via a pull-request - the GitHub repo is now full of relative (rather than absolute) paths to make life easier for anyone that forks the repo.\nI reorganized the Useful Links section at the bottom of the repo to make it more succinct, adding a few more links including Happy Git with R by Jenny Bryan! If you are just getting started with GitHub and want to learn more about Git, GitHub, and using it from within RStudio - check out her resources!\nWays to contribute\nI‚Äôm always on the lookout for interesting datasets, and a way for you to contribute to TidyTuesday beyond a weekly post is submitting a dataset you find in the wild as an Issue on the TidyTuesday repo. Please link to the dataset and add any additional info as to why you thought it was interesting or an article/plot that corresponds to that data.\nI added the Submitting Code Chunks section directly to the readme doc. This is for some code, script, etc that you found useful when working with TidyTuesday. It‚Äôs also a chance for a low-stress pull-request as that‚Äôs how we will be adding code chunks! Please see the guide here about the format to submit.\nImproving my Weekly Tweet Submission Process\nI generally switched between a lot of tabs, eg GitHub, short links, manually adding pics, etc while getting the weekly post setup. I knew there was a way to at least partially automate this, so I looked into my options.\nThe rtweet package has a post to Twitter function via rtweet::post_tweet() which allows you to programmatically post tweets! However - to get where I wanted to be I had to add a few more things and do some interesting refactoring!\nDISCLAIMER\nTo use rtweet for posting you will need to register a Twitter application - please see Mike Kearney‚Äôs great vignette on how to do this.\n\n\n# Basic method of tweeting from rtweet vignette\n\npost_tweet(status = \"my first rtweet #rstats\", media = NULL,\n  token = NULL, in_reply_to_status_id = NULL, destroy_id = NULL,\n  retweet_id = NULL)\n\n\n\nMy Weekly #TidyTuesday Tweet\nIf I simply wanted to post a tweet following the format for #TidyTuesday I could do something like the following.\n\n\nrtweet::post_tweet(\"The @r4dscommunity welcomes you to Week 2 of #TidyTuesday! We're exploring data about *esoteric topic*!\n                   Data: link_to_data\n                   Article: link_to_article\",\n                   media = \"tt_logo.png\")\n\n\n\nHowever this results in the following Tweet:\n\nThis is not exactly what I want‚Ä¶ the text isn‚Äôt aligned properly, I want more than 1 pic, and I really would prefer to use emoji to save characters over Data: and Article:.\nSo on to the next step!\nHadley Wickham has the emo package which allows you to input various emoji into R/R Markdown. This package perfectly solves our emoji needs! I can use code like emo::ji(\"folder\") to get üìÅ or emo::ji(\"news\") to get üì∞!\nBut I still need to get my text aligned properly‚Ä¶ So I broke some formatting rules for normal code, but it got the job done for this rtweet use! Basically, I forced the text to be fully left-aligned, added in some spacing where necessary, and used paste0() to get everything squished together in a coherent tweet (with multiple pics!).\n\n\nrtweet::post_tweet(status = paste0(\n\"The @R4DScommunity welcomes you to week 2 of #TidyTuesday!  We're exploring *esoteric topic*!\n \n\",\n        emo::ji(\"folder\"),\n        \" http://bit.ly/tidyreadme\n\",\n        emo::ji(\"news\"),\n        \" http://cool.article.com\n\n#r4ds #tidyverse #rstats #dataviz\"),\n\n# The below code is relative to my project\n# You need to specify path to the images for tweeting\n\n        media = c(\"tt_logo.png\",\n                  \"tt_rules.png\")\n        )\n\n\n\n\nThis is a great start! However, I want to make this a bit more robust, as I don‚Äôt want to edit it all by hand, when I can generate it programmatically. Refactoring code is always an adventure, so let‚Äôs take a look at our code to see what is static and what changes.\nMix of static and dynamic:\nThe @r4dscommunity welcomes you to week {week} of #Tidy Tuesday\nWe're exploring {data to explore}!\nThe link to the readme is static, but we change the link to an article.\nThe logo and rules are always the same, but up to two additional pics are dynamic.\nSo how do you generate dynamic and static text together? With glue of course! The glue package glues strings together in R, and allows for interpreted strings with the use of {} for example glue::glue(\"Glue is an {adjective} package!\") where the {adjective} indicates an intepreted add-in. So if I had adjective <- \"awesome\" the string would print as \"Glue is an awesome package!\".\nSince we are going to be linking local pics, I‚Äôm also using the here package to make moving between folders in my project easier. My folder is organized like so: TidyTuesday/2019/2019-01-08/.\nSo I can use here::here(\"2019\", \"2019-01-08\", \"pic1.png\") to get the file directory for pic1.png. Since the date 2019-01-08 changes each week, I will also add it as a variable to define.\nAnyway, back to refactoring.\n\n\n# Dynamic Variables\nweek_num <- 2\nexploring <- \"Esoteric data!\"\nshort_link <- \"http://bit.ly/WHATEVER\"\nweek_date <- \"2019-01-08\"\n\n# Static framework\nrtweet::post_tweet(status = glue::glue(\n\"The @R4DScommunity welcomes you to week {week_num} of #TidyTuesday!  We're exploring {exploring}!\n \n\",\n        emo::ji(\"folder\"),\n        \" http://bit.ly/tidyreadme\n\",\n        emo::ji(\"news\"),\n        \" {short_link}\n\n#r4ds #tidyverse #rstats #dataviz\"),\n# The below code is relative to my project\n# You would need to specify path to the images for tweeting\n        media = c(here::here(\"static_img\", \"tt_logo.png\"),   # I have two static pics\n                  here::here(\"static_img\", \"tt_rules.png\"),  # so they go in /static\n                  here::here(\"2019\", week_date, \"pic1.png\"), # notice I have week_date\n                  here::here(\"2019\", week_date, \"pic2.png\")  # here instead of 2019-01-01\n        ))\n\n\n\nNow this will generate the correctly formatted tweet, include the correct additional pictures and text, but more importantly the use of glue and here means I can define the dynamic portions at the top and leave the static body the same.\nHowever, we can refactor things further!\nWe can refactor to a function AND since I only post these tweets on the Monday before #TidyTuesday, I can build variable dates into the function. Really the only thing I need to manually change is what data we are exploring and the short article link.\nBefore we get into the function, I am using a number of packages for my ease.\n\n\n# Packages used in this script\nlibrary(rtweet) # For Tweeting\nlibrary(glue) # For interpretation inside strings\nlibrary(emo) # For emojis!\nlibrary(lubridate) # Working with date-times\nlibrary(here) # Easier file navigation inside projects\nlibrary(purrr) # for pluck - I'm lazy. :shrug:\n\n\n\n\n\n# Only two inputs!\n# exploring = what we are exploring in text\n# short_link = the article link\n\npost_tidytuesday <- function(exploring, short_link){\n        \n        # set date for files structure and names\n        week_date <- as.character(lubridate::today() + 1)\n        \n        # Today's date + 1 = tomorrow\n        # Then time diff between tomorrow and 1st tidytuesday in number of weeks\n        week_num <- as.numeric((lubridate::today() + 1) - lubridate::ymd(20190101))/7 + 1\n        \n        # post the tweet with fill\n        rtweet::post_tweet(status = glue::glue(\n                \"The @R4DScommunity welcomes you to week {week_num} of #TidyTuesday!  We're exploring {exploring}!\n \n\",\n                emo::ji(\"folder\"),\n                \" http://bit.ly/tidyreadme\n\",\n                emo::ji(\"news\"),\n                \" {short_link}\n\n#r4ds #tidyverse #rstats #dataviz\"),\n                \n                # The below code is relative to my project\n                # You need to specify path to the images for tweeting\n                media = c(here::here(\"static_img\", \"tt_logo.png\"),\n                          here::here(\"static_img\", \"tt_rules.png\"),\n                          here::here(\"2019\", week_date, \"pic1.png\"),\n                          here::here(\"2019\", week_date, \"pic1.png\")\n                ))    \n}\n\n\n\nNow we have a nice function and when I want to post on Monday morning, I can just do the following!\n\n\npost_tidytuesday(\n  exploring = \"Esoteric data!\",\n  short_link = \"http://bit.ly/tidy_post\"\n)\n\n\n\nThe link to GitHub for this code.\nPackage Links\nrtweetglueemolubridateherepurrr::pluck()\nStep 2 (for next time)\nHow to improve YOUR #TidyTuesday process and get your code directly from RStudio into Carbon.now.sh for pretty ‚Äúscreenshots‚Äù!\n\n\n\n",
    "preview": "https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/tt_logo.png",
    "last_modified": "2021-03-20T13:32:52+05:30",
    "input_file": {}
  }
]
